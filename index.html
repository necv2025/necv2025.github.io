<!DOCTYPE html>
<!--Adapted from: https://necv2023.github.io/-->
<html lang="en">
    <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.67">
    <meta name="description" content="NECV 2025 website.">
    <meta name="keywords" content="NECV 2025">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <style type="text/css">
        body {
            font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
            font-weight:300;
            font-size:14px;
            margin-left: auto;
            margin-right: auto;
            width: 90%;
            text-align: justify;
            text-justify: inter-word;
            line-height: 1.5;
        }

        h1 {
            font-size:28px;
            font-weight:250;
        }

        h2 {
            font-size:24px;
        }

        h3 {
            font-size:20px;
        }

        h4 {
            font-size:17px;
        }
        .author_list {
            font-size: 10pt;
        }
        .talk_title {
            font-size: 11pt;
            color: #286DC0;
        }

        div.text-box {
            width: 95%;
            padding: 5px;
            border: 4px solid #66cc33;
            margin: 0;
        }
        
        img.header-img {
            border: 1px solid black;
            border-radius: 10px ;
            -moz-border-radius: 10px ;
            -webkit-border-radius: 10px ;
        }
        
        img.rounded {
            border: 1px solid #eeeeee;
            border-radius: 10px ;
            -moz-border-radius: 10px ;
            -webkit-border-radius: 10px ;
        }
        
        a:link,a:visited
        {
            color: #286DC0;
            text-decoration: none;
        }
        a:hover {
            color: #286DC0;
        }
        
        table { 
            border-collapse: collapse; 
            text-align: left;
        }
        table.table1 td.dl-link {
            height: 140px;
            text-align: center;
            font-size: 15px;
        }
        table.table1 > tbody > tr {
          border-top: 1pt solid black;
          border-bottom: 1pt solid black;
        }
        td {
            padding-left: 10px;
            padding-right: 20px;
        }
        .first_col {
            height: 40px;
            /* min-width: 120px; */
        }
        
        img.logo {
          display: block;
          margin-left: auto;
          margin-right: auto;
        }
        
        .vert-cent {
            position: relative;
            top: 50%;
            transform: translateY(-50%);
        }
        
        hr
        {
            border: 0;
            height: 1px;
            background-image: linear-gradient(to right, rgba(0, 0, 0, 0.25), rgba(0, 0, 0, 0.25), rgba(0, 0, 0, 0.25));
        }

        .google-maps {
            width: 100%;
            max-width: 100%;
            display: block;
        }
        .google-maps iframe {
            width: 90% !important; 
            height: 250px; 
            display: block; 
        }

        .underline {
            text-decoration: underline;
        }

        table.table1 > tbody > tr.no_border { border-top: none; border-bottom: none; }

        .table2_container {
            background-color: #FEF9E7;
        }

        .table2 {
            border-collapse: collapse;
        }

        .table2, .table2 *{
            border: none;
        }

        .table2 .sub_first_col {
            padding-left: 15px;
            text-align: right;
        }

        .title {
        }
        .author {
            font-size: 0.8em;
            font-style: italic;
        }
        .university {
            font-size: 0.8em;
            font-style: italic;
        }

        .sponsor_logo {
            margin: 5px;
        }
        
        @media only screen and (min-width: 768px) { 
            body {
                font-size:20px;
                width: 80%;
            }
                
            h1 {
                font-size:38px;
                font-weight:300;
            }
            h2 {
                font-size:32px;
            }
    
            h3 {
                font-size:28px;
            }
    
            h4 {
                font-size:24px;
            }
            .author_list {
                font-size: 12pt;
            }
            .talk_title {
                font-size: 13pt;
            }    
          	table.table1 td.dl-link {
          		height: 160px;
          		font-size: 22px;
          	}
            table.table1 > tbody > tr {
              border-top: 1pt solid black;
              border-bottom: 1pt solid black;
            }

            .google-maps iframe {
                height: 400px;
            }    
        }

        @media only screen and (max-width: 768px) { 
            .sponsor_logo {
                    width: 90%;
                    margin: 20px;
                }
        }

    </style>

    <title>NECV 2025</title>
    </head>
    
  <body>
    <div class="container w-75" align="center">
        <h1><b>New England Computer Vision (NECV) Workshop 2025</b></h1>
        <h2><a href="https://www.umass.edu" target="_blank">University of Massachusetts</a>, Amherst, MA</h2>
        <em><h2>Friday, November 21, 2025</h2></em>
    </div>
    <div class="container w-75" align="center">
        <img src="./files/umass.jpg" width="80%" style="margin: 1em 0em 1em 0em; border: 1px solid #000"><br>
    </div>

    <div class="container w-75" >
        <hr>
        The New England Computer Vision Workshop (NECV) brings together researchers in computer vision and related areas for an informal exchange of ideas through a full day of presentations and posters. Held conveniently after the CVPR deadline and before the NeurIPS conference, NECV offers opportunities to network and showcase research. NECV attracts researchers from universities and industry research labs in New England. As in previous years, the workshop will focus on graduate student presentations. Welcome to UMass Amherst!
        <br>
        <p align="right">
            - <a href="https://gvh.codes" target="_blank">Grant</a> & <a href="https://people.cs.umass.edu/~smaji/" target="_blank">Subhransu</a>
        </p>
    </div>

    <div class="container w-75">
        <hr>
        <h2>Registration and Submission</h2>
        <p>
            <b>Academic researchers</b>:
            Participation is free for all researchers at academic institutions. Please register <a href="https://docs.google.com/forms/d/e/1FAIpQLScWEmPwxTj5smpHx4QfealzuEPwnHVm0HUPS6_8Hl3Uw76dMA/viewform?usp=header">here</a> and submit your abstract <a href="https://docs.google.com/forms/d/e/1FAIpQLSfRSFDN9DhQgNqHhxNGg8CajKy0uJsQTLttrSZoFTGIl_yC3w/viewform?usp=header">here</a>.
            <br><br>
            <b>Industry participants</b>:
            For our industry friends, a limited number of registrations are available for a fee. Please register <a href="https://necv2025.eventbrite.com/">here</a>.
            <br><br>

            <b>Deadlines</b>: Early-bird registration (lunch and parking provided) by <span class="underline">November 11</span>. Please submit your abstract by <span class="underline">November 16</span>. Oral decisions will be released by <span class="underline">November 18</span>.
            <br><br>

            <b>Submission guidelines</b>:
            Please submit a one-page PDF abstract using the <a href="https://github.com/cvpr-org/author-kit/releases/tag/CVPR2026-v1(latex)" target="_blank">CVPR 2026 rebuttal template</a>.
            Please include the title of your work and the list of authors in the abstract.

            You may present work that has already been published or work that is in progress.
            All relevant submissions will be granted a poster presentation,
            and <u>selected submissions from each institution will be granted 12-minute oral presentations</u>.
            Post-docs and faculty may submit for poster presentations, but oral presentations are reserved for graduate students.

            There will be no publications resulting from the workshop,
            so presentations will not be considered "prior peer-reviewed work" according to any definition we are aware of.
            Thus, work presented at NECV can be subsequently submitted to other venues without citation.

            The workshop is after the CVPR submission deadline, so come and show off your new work in a friendly environment.
            It's also just before the NeurIPS conference, so feel free to come and practice your presentation.
            <br><br>
        </p>
    </div>

    <div class="container w-75">
        <hr>
        <h2>Presentation</h2>

        <p>
        <b>Oral presentation</b>:
        Each presentation is allocated a <u>12-minute</u> slot, with an additional <u>3 minutes</u> dedicated to questions and the change of speaker. We request all presenters to bring their own laptop for their presentation. 
        </p>

        <p>
        <b>Poster presentation</b>:
        The poster session will be held in the same room as the oral session (Marriott Room, 11th Floor, Campus Center). Your assigned poster ID can be found on this website. Please locate the correct poster board to display your poster. These boards can accommodate up to <u>57.75" x 46"</u> posters (width x height). You are welcome to use any format within that size limit.
        </p>
        
    </div>

    <div class="container w-75">
        <hr>
        <h2>Logistics</h2>
        
        <h3>Schedule</h3>
        <table class="table1">
            <tbody>
            <tr bgcolor="#E5E8E8">
                <td class="first_col"><b>Time</b></td>
                <td><b>Topic</b></td>
            </tr>
            <tr>
                <td class="first_col">9:00-9:50</td>
                <td>Registration, Poster Setup & Breakfast</td>
            </tr>
            <tr>
                <td class="first_col">9:50-10:00</td>
                <td>Opening Remarks</td>
            </tr>
            <tr>
                <td class="first_col">10:00-11:30</td>
                <td><b>Oral Session I</b></td>
            </tr>
            <tr>
                <td class="table2_container" colspan="2">
                    <table class="table2">
                        <tr>
                            <td class="sub_first_col">[10:00]</td>
                            <td><span class="title">Not All Birds Look The Same: Identity-Preserving Generation For Birds</span>, <span class="author">Aaron Sun</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[10:15]</td>
                            <td><span class="title">Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos</span>, <span class="author">Xavier Thomas</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[10:30]</td>
                            <td><span class="title">CObL: Toward Zero-Shot Ordinal Layering without User Prompting</span>, <span class="author">Aneel Damaraju</span>, <span class="university">Harvard University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[10:45]</td>
                            <td><span class="title">Consensus-Driven Active Model Selection</span>, <span class="author">Justin Kay</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[11:00]</td>
                            <td><span class="title">Struct2D: A Perception-Guided Framework for Spatial Reasoning in MLLMs</span>, <span class="author">Hanhui Wang</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[11:15]</td>
                            <td><span class="title">Structured Light with a Million Light Planes per Second</span>, <span class="author">Dhawal Sirikonda</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                    </table>
                </td>
            </tr>
            <tr>
                <td class="first_col">11:30-12:30</td>
                <td><b>Coffee & Poster Session I</b></td>
            </tr>
            <tr>
                <td class="table2_container" colspan="2">
                    <table class="table2">
                        <tr>
                            <td class="sub_first_col">[1]</td><td><span class="title">Tell the Story, Not the Frames: Narrative-Aware Retrieval for Audio Description</span>, <span class="author">Seung Hyun Hahm</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[2]</td><td><span class="title">Relational Representation Learning</span>, <span class="author">Ian Hajra</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[3]</td><td><span class="title">Progressive Stereo Edge Correspondences and Refinement</span>, <span class="author">Chiang-Heng Chien</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[4]</td><td><span class="title">Learning and Stabilizing Isometries for Robust Vision</span>, <span class="author">Javid Lakha</span>, <span class="university">Harvard University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[5]</td><td><span class="title">stable-worldmodel: An Ecosystem For World Model Research</span>, <span class="author">Lucas Maes</span>, <span class="university">Mila</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[6]</td><td><span class="title">Augmented Reality Active Area Labels for Dynamic Scenes</span>, <span class="author">Lana Yang-Maccini</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[7]</td><td><span class="title">Exploring Texture Guidance in Diffusion Models</span>, <span class="author">Eric Yee</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[8]</td><td><span class="title">PackUV: Packed Gaussian UV Maps for 4D Volumetric Video</span>, <span class="author">Aashish Rai</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[9]</td><td><span class="title">Compositional Targeted Multi-Label Universal Perturbations</span>, <span class="author">Hassan Mahmood</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[10]</td><td><span class="title">Blind to Shape, Bound to Semantics: A VLMâ€™s Dilemma</span>, <span class="author">Zachary Meurer</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[11]</td><td><span class="title">Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</span>, <span class="author">Leyang Hu</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[12]</td><td><span class="title">FLIGHT: Fibonacci Lattice-based Inference for Geometric Heading in real-Time</span>, <span class="author">Dave Dirnfeld</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[13]</td><td><span class="title">ID-Sim: An Identity-Focused Perceptual Similarity Metric</span>, <span class="author">Nayoung Chae</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[14]</td><td><span class="title">Enhancing Autonomous Navigation by Imaging Hidden Objects using Single-Photon LiDAR</span>, <span class="author">Nevindu Batagoda</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[15]</td><td><span class="title">Audio Geolocation: An Investigation with Natural Sounds</span>, <span class="author">Wuao Liu</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[16]</td><td><span class="title">Some Modalities are More Equal Than Others: Decoding and Architecting Multimodal Integration in MLLMs</span>, <span class="author">Tianle Chen</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[17]</td><td><span class="title">Do VLMs see texture like humans and CNNs? Evidence from slant-from-texture</span>, <span class="author">Qian Zhang</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[18]</td><td><span class="title">A Monte Carlo Rendering Framework for Simulating Optical Heterodyne Detection</span>, <span class="author">Juhyeon Kim</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[19]</td><td><span class="title">LVT: Large-Scale Scene Reconstruction via Local View Transformers</span>, <span class="author">Tooba Imtiaz</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[20]</td><td><span class="title">HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Models</span>, <span class="author">Yiwen Chen</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[21]</td><td><span class="title">Iris: Integrating Language into Diffusion-based Monocular Depth Estimation</span>, <span class="author">Ziyao Zeng</span>, <span class="university">Yale University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[22]</td><td><span class="title">Coffee: Controllable Diffusion Fine-tuning</span>, <span class="author">Ziyao Zeng</span>, <span class="university">Yale University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[23]</td><td><span class="title">BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models</span>, <span class="author">Shengao Wang</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[24]</td><td><span class="title">DevCV Toolbox: Toward Developmentally Grounded Benchmarking of Vision Foundation Models</span>, <span class="author">Max Whitton</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[25]</td><td><span class="title">PRISM: Controllable Diffusion for Compound Image Restoration with Scientific Fidelity</span>, <span class="author">Rupa Kurinchi-Vendhan</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[26]</td><td><span class="title">Words That Make Language Models Perceive</span>, <span class="author">Sophie Wang</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[27]</td><td><span class="title">Active Measurement: Efficient Estimation at Scale</span>, <span class="author">Max Hamilton</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[28]</td><td><span class="title">Spatially-Varying Autofocus</span>, <span class="author">Yingsi Qin</span>, <span class="university">Carnegie Mellon University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[29]</td><td><span class="title">VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning</span>, <span class="author">Lingxiao Li</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[30]</td><td><span class="title">Residual Primitive Fitting of 3D Shapes with SuperFrusta</span>, <span class="author">Aditya Ganeshan</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[31]</td><td><span class="title">CHAIR : An interpretable pipeline for AI-expert collaboration on elephant Re-identification</span>, <span class="author">Antoine Salaun</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[32]</td><td><span class="title">The LLM Bottleneck: Why Open-Source Vision LLMs Struggle with Hierarchical Visual Recognition</span>, <span class="author">Yuwen Tan</span>, <span class="university">Boston University</span></td>
                        </tr>
                    </table>
                </td>
            <tr>
            <tr>
                <td class="first_col">12:30-2:00</td>
                <td>Lunch</td>
            </tr>
            <tr>
                <td class="first_col">2:00-3:00</td>
                <td><b>Coffee & Poster Session II</b></td>
            </tr>
            <tr>
                <td class="table2_container" colspan="2">
                    <table class="table2">
                        <tr>
                            <td class="sub_first_col">[1]</td><td><span class="title">Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos</span>, <span class="author">Xavier Thomas</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[2]</td><td><span class="title">Looking at the Sky</span>, <span class="author">Shrenik Borad</span>, <span class="university">George Washington University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[3]</td><td><span class="title">Not All Birds Look The Same: Identity-Preserving Generation For Birds</span>, <span class="author">Aaron Sun</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[4]</td><td><span class="title">Super-Resolution with Structured Motion</span>, <span class="author">Gabby Litterio</span>, <span class="university">Brown University </span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[5]</td><td><span class="title">PLLM: Pseudo-Labeling Large Language Models for CAD Program Synthesis</span>, <span class="author">Yuanbo Li</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[6]</td><td><span class="title">Unsafe2Safe: Controllable Image Anonymization for Downstream Utility</span>, <span class="author">Minh Dinh</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[7]</td><td><span class="title">Exploring Efficient and Practical Unified Unified Multimodal Model</span>, <span class="author">Xu Ma</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[8]</td><td><span class="title">Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention</span>, <span class="author">Yuyao Zhang</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[9]</td><td><span class="title">LayerCraft-Enhancing Text-to-Image Generation with CoT Reasoning and Layered Object Integration</span>, <span class="author">Yuyao Zhang</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[10]</td><td><span class="title">Outlier-Aware Post-Training Quantization for Image Super-Resolution</span>, <span class="author">Hailing Wang</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[11]</td><td><span class="title">Does learning about time improve out-of-distribution generalization in object detection?</span>, <span class="author">Kai Van Brunt</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[12]</td><td><span class="title">Vision Masked Image Modeling Transfers Across Domains</span>, <span class="author">Pranav Sankar</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[13]</td><td><span class="title">Can LVLMs Harness Visual Contexts to Untangle Ambiguity In Language?</span>, <span class="author">Heejeong Nam</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[14]</td><td><span class="title">SNAP: Towards Segmenting Anything in Any Point Cloud</span>, <span class="author">Aniket Gupta</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[15]</td><td><span class="title">Trace Anything: Representing Any Video in 4D via Trajectory Fields</span>, <span class="author">Xinhang Liu</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[16]</td><td><span class="title">LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction</span>, <span class="author">Tianye Ding</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[17]</td><td><span class="title">RealBirdID: Benchmarking Bird Species Identification in the Era of MLLMs</span>, <span class="author">Logan Lawrence</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[18]</td><td><span class="title">Combining Translation with Magnification to Resolve Ambiguity in Super-Resolution</span>, <span class="author">Daniel Fu</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[19]</td><td><span class="title">DIET-CP: Lightweight and Data Efficient Self Supervised Continued Pretraining</span>, <span class="author">Jakob Ambsdorf</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[20]</td><td><span class="title">Potion Brewing Laboratory: An Environment for Continual Learning in World Models</span>, <span class="author">Taj Gillin</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[21]</td><td><span class="title">CObL: Toward Zero-Shot Ordinal Layering without User Prompting</span>, <span class="author">Aneel Damaraju</span>, <span class="university">Harvard University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[22]</td><td><span class="title">Consensus-Driven Active Model Selection</span>, <span class="author">Justin Kay</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[23]</td><td><span class="title">Struct2D: A Perception-Guided Framework for Spatial Reasoning in MLLMs</span>, <span class="author">Hanhui Wang</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[24]</td><td><span class="title">Attribution Robustness via Implicit Curvature Regularization</span>, <span class="author">Matteo Gamba</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[25]</td><td><span class="title">Discontinuous 2D Neural Fields without Meshing</span>, <span class="author">Javid Lakha</span>, <span class="university">Harvard University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[26]</td><td><span class="title">S3: Learnable Spline-Wavelets for State Space Models</span>, <span class="author">Daniel Cai</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[27]</td><td><span class="title">SimpleCall: A Lightweight Image Restoration Agent in Label-Free Environments with MLLM Perceptual Feedback</span>, <span class="author">Jianglin Lu</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[28]</td><td><span class="title">SuperRivolution: Fine-Scale Rivers from Coarse Temporal Satellite Imagery</span>, <span class="author">Rangel Daroya</span>, <span class="university">UMass Amherst</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[29]</td><td><span class="title">Underwater Optical Backscatter Communication using Acousto-Optic Beam Steering</span>, <span class="author">Dhawal Sirikonda</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[30]</td><td><span class="title">Structured Light with a Million Light Planes per Second</span>, <span class="author">Dhawal Sirikonda</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[31]</td><td><span class="title">Arbitrary-Scale 3D Gaussian Super-Resolution</span>, <span class="author">Huimin Zeng</span>, <span class="university">Northeastern University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[32]</td><td><span class="title">3D Curvix: From Multiview 2D Edges to 3D Curve Segments</span>, <span class="author">Chiang-Heng Chien</span>, <span class="university">Brown University</span></td>
                        </tr>
                     </table>
                </td>
            </tr>
            <tr>
                <td class="first_col">3:00-4:30</td>
                <td><b>Oral Session II</b></td>
            </tr>
            <tr>
                <td class="table2_container" colspan="2">
                    <table class="table2">
                        <tr>
                            <td class="sub_first_col">[3:00]</td>
                            <td><span class="title">Tell the Story, Not the Frames: Narrative-Aware Retrieval for Audio Description</span>, <span class="author">Seung Hyun Hahm</span>, <span class="university">Dartmouth College</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[3:15]</td>
                            <td><span class="title">Curvature Tuning: Provable Training-free Model Steering From a Single Parameter</span>, <span class="author">Leyang Hu</span>, <span class="university">Brown University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[3:30]</td>
                            <td><span class="title">Iris: Integrating Language into Diffusion-based Monocular Depth Estimation</span>, <span class="author">Ziyao Zeng</span>, <span class="university">Yale University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[3:45]</td>
                            <td><span class="title">BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models</span>, <span class="author">Shengao Wang</span>, <span class="university">Boston University</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[4:00]</td>
                            <td><span class="title">Words That Make Language Models Perceive</span>, <span class="author">Sophie Wang</span>, <span class="university">MIT</span></td>
                        </tr>
                        <tr>
                            <td class="sub_first_col">[4:15]</td>
                            <td><span class="title">Residual Primitive Fitting of 3D Shapes with SuperFrusta</span>, <span class="author">Aditya Ganeshan</span>, <span class="university">Brown University</span></td>
                        </tr>
                    </table>
                </td>
            <tr>
                <td class="first_col">4:30-4:45</td>
                <td>Closing Remarks</td>
            </tr>
            </tbody>
        </table>
        

        <h3>Venue</h3>
        <p>The workshop will be held in the <a href="https://maps.app.goo.gl/Cp79u6RjNjwKoJNR9" target="_blank">Marriott Room, 11th Floor, Campus Center, University of Massachusetts, Amherst</a>.</p>
        
        <h3>Parking</h3>
        <p>If you signed up by the early registration deadline we will pay for your parking. Please follow these instructions:
            <ul>
                <li>Park at the <a href="https://maps.app.goo.gl/9jDSFfiocpFsmNCq7" target="_blank">Campus Center Parking Garage</a> at Levels 2-6.</li>
                <li><u>Do not</u> pay for parking.</li>
                <li>Proceed to the registration desk at the Marriott Room, 11th Floor, Campus Center.</li>
                <li>You will receive a link at the registration desk that you can use within 20 minutes of your arrival to register your car for parking.</li>
            </ul>
        If you did not sign up by the early registration deadline, the <a href="https://maps.app.goo.gl/9jDSFfiocpFsmNCq7" target="_blank">Campus Center Parking Garage</a> is still the most convenient parking location and you can use the parking kiosks to pay for parking. The rate is $1.85/hr.
        </p>
    </div>
    
    <div class="container w-75">
        <hr>
        <h2>Sponsorship</h2>
            <p>
                <a href="https://www.merl.com"><img class="sponsor_logo" src="files/merl.svg" alt="Mitsubishi Electric Research Laboratories" width="400"/></a>
                <a href="https://ds.cs.umass.edu"><img class="sponsor_logo" src="files/cds.png" alt="Center for Data Science and Artificial Intelligence" width="700"/></a>
            </p>
    </div>

    <div class="container w-75">
        <hr>
        <h2>Organizers</h2>
            <p>
                <b>Host</b>:
                <a href="https://gvh.codes" target="_blank">Grant Van Horn</a> and <a href="https://people.cs.umass.edu/~smaji/" target="_blank">Subhransu Maji</a>.
            <p>

            <p>
                <b>Program committee</b>:
                <a href="https://deepc94.github.io">Deep Chakraborty</a>, 
                <a href="https://mustafa1728.github.io">Mustafa Chasmai</a>,
                <a href="https://rangeldaroya.github.io">Rangel Daroya</a>, 
                <a href="https://johnmaxh.github.io">Max Hamilton</a>,
                <a href="https://www.loganlawrence.info">Logan Lawrence</a>, 
                <a href="https://wuao652.github.io">Wuao Liu</a>, 
                <a href="https://aaronsun1030.github.io">Aaron Sun</a>, and
                <a href="https://vikastmz.github.io">Vikas Thamizharasan</a>.
            </p>

            <p>
                <b>Logistics committee</b>:
                <a href="https://rangeldaroya.github.io">Rangel Daroya</a> and 
                <a href="https://www.loganlawrence.info">Logan Lawrence</a>.
            </p>
            
            <p>
                <b>Corporate relations chair</b>:
                Samson Timoner.
            </p>

            <p>
                <b>Website chair</b>:
                <a href="https://fabiendelattre.com">Fabien Delattre</a>.
            </p>

            <p>
                <b>Steering committee</b>:
                Erik Learned-Miller (UMass Amherst), Kate Saenko (Boston University), Yun (Raymond) Fu (Northeastern University), Octavia Camps (Northeastern University), Todd Zickler (Harvard), James Tompkin (Brown), Benjamin Kimia (Brown), Phillip Isola (MIT), Pulkit Agrawal (MIT), SouYoung Jin (Dartmouth), Adithya Pediredla (Dartmouth), Yu-Wing Tai (Dartmouth), and Alex Wong (Yale).
            </p>
    </div>
    <div class="container w-75"></div>
        <hr>
        <h2>Past Years</h2>
        <ul>
            <li>2024 - <a href="https://necv2024.github.io" target="_blank">Yale University</a></li>
            <li>2023 - <a href="https://necv2023.github.io/" target="_blank">Dartmouth College</a></li>
            <li>2022 - <a href="https://necv2022.github.io/" target="_blank">Massachusetts Institute of Technology</a></li>
            <li>2019 - <a href="https://visual.cs.brown.edu/workshops/necv2019/" target="_blank">Brown University</a></li>
            <li>2018 - <a href="https://projects.iq.harvard.edu/necv2018/" target="_blank">Harvard University</a></li>
            <li>2017 - <a href="https://web.northeastern.edu/smilelab/necv2017/index.html" target="_blank">Northeastern University</a></li>
            <li>2016 - <a href="http://vision.cs.uml.edu/necv2016.html" target="_blank">Boston University</a></li>
            <li>2015 - <a href="https://people.cs.umass.edu/~smaji/nevm2015/" target="_blank">University of Massachusetts Amherst</a></li>
        </ul>
    </div>
</body></html>
